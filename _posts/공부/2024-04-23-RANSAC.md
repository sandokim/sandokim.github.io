---
title: "[3D CV] RANSAC"
last_modified_at: 2024-04-23
categories:
  - 공부
tags:
  - Multiple View Geometry
  - RANSAC
  - 3D CV
excerpt: "RANSAC 정리"
use_math: true
classes: wide
---

> [[Blog](https://gaussian37.github.io/vision-concept-ransac/)] 

본 포스트는 위 블로그 내용을 참조하여 정리한 내용임을 밝힙니다.

### RANSAC의 장단점

지금까지 살펴본 내용으로 설명을 하면 

① RANSAC의 가장 큰 장점은 outlier에 강건한 모델이라는 점입니다. 
이 장점이 RANSAC을 사용하는 가장 큰 이유이기도 합니다. 
따라서 outlier가 어느 정도 섞여있어도 그것들을 무시하고 모델링 할 수 있습니다.

② RANSAC은 outlier에 강건한 모델을 설계하는 방법 중 가장 쉬운 방법입니다. 
inlier의 갯수만 세면 되기 때문에 구현도 쉽고 어떠한 모델이라도 적용하기도 쉽습니다.

반면 ① RANSAC은 랜덤 샘플이라는 방법을 이용하므로 Non-deterministic하다는 단점이 있습니다. 
즉, 같은 데이터 셋을 이용하여 모델링하더라도 매번 실행 결과가 다를 수 있다는 것입니다. 
이 점은 관점에 따라서 RANSAC의 장점이 될 수도 있고 단점이 될 수도 있다고 생각합니다. 
하지만 모델의 재현성 관점에서는 단점이라고 볼 수 있습니다.

두번째 단점은 RANSAC의 가장 치명적인 단점입니다. 
만약 outlier가 노이즈 처럼 생기지 않고 특정 분포를 가지게 되면 모델이 outlier를 fitting 할 수 있습니다. 
따라서 데이터 셋을 미리 확인하고 outlier가 얼만큼 있는 지와 outlier가 특정 패턴 및 분포를 가지는 지 사전에 확인하는 것은 매우 중요합니다. 
만약 특정 분포를 가진다면 오히려 다른 방법으로 outlier를 사전에 제거하는 것도 좋은 접근이 될 수 있기 때문입니다.
또한 RANSAC은 threshold 파라미터에 큰 영향을 받는다는 단점이 있습니다. 
threshold를 너무 작게 설정하면 모델이 안정적으로 fitting이 되지 않을 수 있고 데이터의 변화에 민감하게 반응합니다. 
반면 threshold를 크게 잡으면 outlier까지 inlier로 판단할 수 있으므로 모델이 정상적으로 fitting할 수 없게됩니다. 
뿐만 아니라 inlier의 분포가 계속 변하게 된다면 threshold 기준 또한 adaptive하게 변해야 할 수 있습니다. 
이러한 모든 것들을 반영하여 threshold를 정하는 것이 어렵다는 것이 RANSAC의 주요 단점 중의 하나입니다.

마지막으로 RANSAC은 Loss를 기반으로 동작하는 L1, L2 Loss와는 다르게 Loss를 기반으로 모델 fitting을 하지 않습니다. 
이러한 동작 방식이 다른 알고리즘과 연계되어 한번에 Loss를 계산하는 pipeline에 연결시킬 수 없다는 점이 단점이 될 수 있습니다. 
왜냐하면 다양한 알고리즘이 머신러닝, 딥러닝 방식의 학습 방식으로 이루어지기 때문에 같은 pipeline으로 연결할 수 있으면 한번에 전체 pipeline을 학습할 수 있어서 효율적이기 때문입니다.
